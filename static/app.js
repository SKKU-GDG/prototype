const sentenceInput = document.getElementById('sentenceInput');
const recordButton = document.getElementById('recordButton');
const stopButton = document.getElementById('stopButton');
const feedbackDiv = document.getElementById('feedback');

let mediaRecorder;
let audioChunks = [];
let audioStream;

recordButton.addEventListener('click', async () => {
    const sentence = sentenceInput.value.trim();
    if (!sentence) {
        alert('Please enter a sentence to practice!');
        return;
    }

    try {
        audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(audioStream, { mimeType: 'audio/webm;codecs=opus' });

        audioChunks = [];

        mediaRecorder.ondataavailable = event => {
            audioChunks.push(event.data);
        };

        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            sendAudioToServer(audioBlob, sentence);
        };

        mediaRecorder.start();
        recordButton.disabled = true; 
        stopButton.disabled = false;  
        feedbackDiv.innerHTML = 'âœ¨ Recording... Please pronounce the sentence clearly! âœ¨';

    } catch (err) {
        console.error('Microphone access error:', err);
        alert('Please allow microphone access (check browser settings)');
    }
});

// Stop recording button click event listener
stopButton.addEventListener('click', () => {
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop(); // Stop recording
        // Stop microphone stream tracks to turn off mic icon and release resources
        audioStream.getTracks().forEach(track => track.stop());
    }
    recordButton.disabled = false; // ë…¹ìŒ ì¤‘ì§€ í›„ ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í™œì„±í™”
    stopButton.disabled = true;  // ë…¹ìŒ ì¤‘ì§€ ë²„íŠ¼ ë¹„í™œì„±í™”
    feedbackDiv.innerHTML = 'â³ Analyzing speech... Please wait a moment! â³';
});

// Function to send audio data and sentence to backend server
async function sendAudioToServer(audioBlob, sentence) {
    const formData = new FormData();
    // Add audio Blob and original sentence to FormData
    formData.append('audio', audioBlob, 'pronunciation.webm'); // File name with correct extension
    formData.append('sentence', sentence);

    try {
        // Send POST request to Flask backend '/analyze-pronunciation' endpoint
        const response = await fetch('/analyze-pronunciation', {
            method: 'POST',
            body: formData // FormData ê°ì²´ëŠ” ìë™ìœ¼ë¡œ 'multipart/form-data'ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.
        });

        // ì‘ë‹µ ìƒíƒœê°€ ì„±ê³µ(2xx)ì´ ì•„ë‹ˆë©´ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
        if (!response.ok) {
            const errorText = await response.text(); // ì„œë²„ì—ì„œ ë³´ë‚¸ ì˜¤ë¥˜ ë©”ì‹œì§€ í™•ì¸
            throw new Error(`HTTP error! status: ${response.status} - ${errorText}`);
        }

        const data = await response.json(); // ì„œë²„ ì‘ë‹µì„ JSON í˜•íƒœë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        // ë°›ì€ í”¼ë“œë°±ì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
        feedbackDiv.innerHTML = `
            <h3>ğŸ¤ ì¸ì‹ëœ ë°œìŒ:</h3>
            <p class="transcribed-text">${data.transcribed_text || 'ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}</p>
            <h3>ğŸ“¢ Geminiì˜ í”¼ë“œë°±:</h3>
            <p>${data.feedback || 'í”¼ë“œë°±ì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}</p>`;

    } catch (error) {
        console.error('ìŒì„± ì „ì†¡ ë˜ëŠ” ë¶„ì„ ì˜¤ë¥˜:', error);
        feedbackDiv.innerHTML = `ğŸš¨ An error occurred. Please try again.<br>Error details: ${error.message}`;
    }
}